{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Stream 3 Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "\n",
    "import pandas as pd # Data manipulation\n",
    "import numpy as np # Matrix calculation\n",
    "import geopandas as gpd # GIS of Pandas\n",
    "import seaborn as sb # Data visualization\n",
    "import matplotlib.pyplot as plt # Data visualization\n",
    "from shapely.geometry import Point #For geojson\n",
    "from sklearn.preprocessing import StandardScaler #For ML\n",
    "from sklearn.cluster import SpectralClustering, KMeans #For ML\n",
    "from sklearn.metrics import silhouette_score #For ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Aggregated Yield Data\n",
    "df_agg_00_23=pd.read_csv('C:/Users/nsain/Downloads/rm_yield_00_23_major_crops.csv')\n",
    "\n",
    "# Reading GIS\n",
    "gdf_rm=gpd.read_file('C:/Users/nsain/Downloads/RM_shapefile/RuralMunicipality.shp')\n",
    "\n",
    "# Reading Yield Data\n",
    "df_rm_yields=pd.read_csv('C:/Users/nsain/Downloads/rm-yields-data.csv')\n",
    "\n",
    "# Changing data type \n",
    "gdf_rm['RMNO']=gdf_rm['RMNO'].astype(int)\n",
    "gdf_rm_clean=gdf_rm[['RMNO', 'RMNM','geometry']].rename(columns={'RMNO': 'RM'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning Data\n",
    "df_major_crops=df_rm_yields[['Year', 'RM', 'Spring Wheat']]\n",
    "gdf_rm_yield=pd.merge(gdf_rm_clean.rename(columns={'RMNO':'RM'}), df_major_crops, on='RM', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yearly Spring Wheat Yields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of crops to include in plots\n",
    "crops = ['Spring Wheat']\n",
    "\n",
    "# List of years to include in subplots\n",
    "years = list(range(2014, 2023 + 1))\n",
    "\n",
    "# Function to plot yield data for a specific crop\n",
    "def plot_yield_by_year(crop):\n",
    "    # Set up the figure with 2 rows and 5 columns for the 10 subplots\n",
    "    fig, axs = plt.subplots(2, 5, figsize=(20, 16))\n",
    "    fig.suptitle(f'{crop} Yield per Year (2014 - 2023)', color='teal', size=20)\n",
    "    \n",
    "    # Flatten the axs array for easy indexing\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    # Loop through each year and plot it on its respective subplot\n",
    "    for i, year in enumerate(years):\n",
    "        ax = axs[i]\n",
    "        gdf_rm_yield[gdf_rm_yield['Year'] == year].plot(\n",
    "            column=crop,\n",
    "            cmap='RdYlGn',\n",
    "            legend=False,\n",
    "            ax=ax,\n",
    "            edgecolor='black'\n",
    "        )\n",
    "        ax.set_title(f'Year: {year}', color='teal', size=12)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_xlabel('')\n",
    "        ax.set_ylabel('')\n",
    "    \n",
    "    # Adjust the spacing between subplots for readability\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "# Generate plots for each crop\n",
    "for crop in crops:\n",
    "    plot_yield_by_year(crop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsupervised Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elbow Method and Silhouette Score\n",
    "crops = ['Spring Wheat']\n",
    "\n",
    "# Function to prepare data for each crop\n",
    "def prepare_data_for_crop(df, crop):\n",
    "    columns = [f'{crop}_mean', f'{crop}_std']\n",
    "    crop_data = df[columns].dropna().values\n",
    "    return crop_data\n",
    "\n",
    "# Standardize the data\n",
    "def standardize_data(data):\n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = scaler.fit_transform(data)\n",
    "    return data_scaled\n",
    "\n",
    "# Function to perform spectral clustering and choose the optimal number of clusters\n",
    "def spectral_clustering(data, n_clusters):\n",
    "    clustering = SpectralClustering(n_clusters=n_clusters, assign_labels=\"discretize\", random_state=0)\n",
    "    labels = clustering.fit_predict(data)\n",
    "    return labels\n",
    "\n",
    "# Function to find the optimal number of clusters using KMeans for the Elbow Method\n",
    "def find_optimal_clusters(data, max_k):\n",
    "    sse = []\n",
    "    silhouette_scores = []\n",
    "    for k in range(2, max_k+1):\n",
    "        kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "        labels = kmeans.fit_predict(data)\n",
    "        sse.append(kmeans.inertia_)\n",
    "        silhouette_scores.append(silhouette_score(data, labels))\n",
    "    optimal_k = silhouette_scores.index(max(silhouette_scores)) + 2\n",
    "    return optimal_k, sse, silhouette_scores\n",
    "\n",
    "# Iterate over each crop and perform clustering\n",
    "for crop in crops:\n",
    "    # Prepare the data for the crop\n",
    "    crop_data = prepare_data_for_crop(df_agg_00_23, crop)\n",
    "    \n",
    "    # Standardize the data\n",
    "    crop_data_scaled = standardize_data(crop_data)\n",
    "    \n",
    "    # Find the optimal number of clusters using KMeans for the Elbow Method\n",
    "    optimal_k, sse, silhouette_scores = find_optimal_clusters(crop_data_scaled, 10)\n",
    "    \n",
    "    # Perform spectral clustering with the optimal number of clusters\n",
    "    labels = spectral_clustering(crop_data_scaled, optimal_k)\n",
    "    \n",
    "    # Add the cluster labels to the original dataframe\n",
    "    df_agg_00_23[f'{crop}_Spectral_Cluster_Optimal'] = np.nan\n",
    "    df_agg_00_23.loc[~df_agg_00_23[[f'{crop}_mean', f'{crop}_std']].isna().any(axis=1), f'{crop}_Spectral_Cluster_Optimal'] = labels\n",
    "    \n",
    "    # Print the results\n",
    "    print(f'Optimal number of clusters for {crop}: {optimal_k}')\n",
    "    print(f'Silhouette scores for {crop}: {silhouette_scores}')\n",
    "    \n",
    "    # Visualize the Elbow Method and Silhouette Method in one graph\n",
    "    fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    color = 'tab:blue'\n",
    "    ax1.set_xlabel('Number of clusters (k)')\n",
    "    ax1.set_ylabel('Sum of squared distances (SSE)', color=color)\n",
    "    ax1.plot(range(2, 11), sse, marker='o', color=color, label='SSE (Elbow Method)')\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "    \n",
    "    ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "    color = 'tab:red'\n",
    "    ax2.set_ylabel('Silhouette Score', color=color)\n",
    "    ax2.plot(range(2, 11), silhouette_scores, marker='o', color=color, linestyle='dashed', label='Silhouette Score')\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "    \n",
    "    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "    plt.title(f'Elbow Method and Silhouette Method for {crop}')\n",
    "    fig.legend(loc='upper right', bbox_to_anchor=(0.85, 0.85))\n",
    "    plt.show()\n",
    "    \n",
    "    # Visualize the clustering results\n",
    "    plt.scatter(df_agg_00_23[f'{crop}_mean'], df_agg_00_23[f'{crop}_std'], c=df_agg_00_23[f'{crop}_Spectral_Cluster_Optimal'], cmap='RdYlGn')\n",
    "    plt.title(f'Spectral Clustering Results for {crop}')\n",
    "    plt.xlabel(f'{crop}_mean')\n",
    "    plt.ylabel(f'{crop}_std')\n",
    "    plt.colorbar(label='Cluster')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spectral Clustering in ML Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming df_agg_00_23 is already loaded\n",
    "crops = ['Canola', 'Spring Wheat', 'Durum', 'Oats', 'Lentils', 'Peas', 'Barley']\n",
    "\n",
    "# Function to prepare data for each crop\n",
    "def prepare_data_for_crop(df, crop):\n",
    "    columns = [f'{crop}_mean', f'{crop}_std']\n",
    "    crop_data = df[columns].dropna().values\n",
    "    return crop_data\n",
    "\n",
    "# Standardize the data\n",
    "def standardize_data(data):\n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = scaler.fit_transform(data)\n",
    "    return data_scaled\n",
    "\n",
    "# Function to perform spectral clustering and choose the optimal number of clusters\n",
    "def spectral_clustering(data, n_clusters):\n",
    "    clustering = SpectralClustering(n_clusters=n_clusters, assign_labels=\"discretize\", random_state=0)\n",
    "    labels = clustering.fit_predict(data)\n",
    "    return labels\n",
    "\n",
    "# Function to find the optimal number of clusters\n",
    "def find_optimal_clusters(data, max_k):\n",
    "    scores = []\n",
    "    for k in range(2, max_k+1):\n",
    "        labels = spectral_clustering(data, k)\n",
    "        score = silhouette_score(data, labels)\n",
    "        scores.append(score)\n",
    "    optimal_k = scores.index(max(scores)) + 2\n",
    "    return optimal_k, scores\n",
    "\n",
    "# Iterate over each crop and perform clustering\n",
    "for crop in crops:\n",
    "    # Prepare the data for the crop\n",
    "    crop_data = prepare_data_for_crop(df_agg_00_23, crop)\n",
    "    \n",
    "    # Standardize the data\n",
    "    crop_data_scaled = standardize_data(crop_data)\n",
    "    \n",
    "    # Find the optimal number of clusters\n",
    "    optimal_k, scores = find_optimal_clusters(crop_data_scaled, 10)\n",
    "    \n",
    "    # Perform spectral clustering with the optimal number of clusters\n",
    "    labels = spectral_clustering(crop_data_scaled, optimal_k)\n",
    "    \n",
    "    # Add the cluster labels to the original dataframe\n",
    "    df_agg_00_23[f'{crop}_Spectral_Cluster_Optimal'] = np.nan\n",
    "    df_agg_00_23.loc[~df_agg_00_23[[f'{crop}_mean', f'{crop}_std']].isna().any(axis=1), f'{crop}_Spectral_Cluster_Optimal'] = labels\n",
    "    \n",
    "    # Print the results\n",
    "    print(f'Optimal number of clusters for {crop}: {optimal_k}')\n",
    "    print(f'Silhouette scores for {crop}: {scores}')\n",
    "    \n",
    "    # Visualize the silhouette scores\n",
    "    plt.plot(range(2, 11), scores, marker='o')\n",
    "    plt.title(f'Silhouette Scores for {crop}')\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('Silhouette Score')\n",
    "    plt.show()\n",
    "    \n",
    "    # Visualize the clustering results\n",
    "    plt.scatter(df_agg_00_23[f'{crop}_mean'], df_agg_00_23[f'{crop}_std'], c=df_agg_00_23[f'{crop}_Spectral_Cluster_Optimal'], cmap='RdYlGn')\n",
    "    plt.title(f'Spectral Clustering Results for {crop}')\n",
    "    plt.xlabel(f'{crop}_mean')\n",
    "    plt.ylabel(f'{crop}_std')\n",
    "    plt.colorbar(label='Cluster')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customized Clusters by Expert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming df_agg_00_23 is already loaded\n",
    "crops = ['Canola', 'Spring Wheat', 'Durum', 'Oats', 'Lentils', 'Peas', 'Barley']\n",
    "\n",
    "# Function to prepare data for each crop\n",
    "def prepare_data_for_crop(df, crop):\n",
    "    columns = [f'{crop}_mean', f'{crop}_std']\n",
    "    crop_data = df[columns].dropna().values\n",
    "    return crop_data, df[columns].dropna().index\n",
    "\n",
    "# Standardize the data\n",
    "def standardize_data(data):\n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = scaler.fit_transform(data)\n",
    "    return data_scaled\n",
    "\n",
    "# Perform spectral clustering with a fixed number of clusters\n",
    "def perform_spectral_clustering(data, n_clusters=5):\n",
    "    clustering = SpectralClustering(n_clusters=n_clusters, assign_labels=\"discretize\", random_state=0)\n",
    "    labels = clustering.fit_predict(data)\n",
    "    return labels\n",
    "\n",
    "# Iterate over each crop and perform clustering\n",
    "for crop in crops:\n",
    "    # Prepare the data for the crop\n",
    "    crop_data, indices = prepare_data_for_crop(df_agg_00_23, crop)\n",
    "    \n",
    "    # Standardize the data\n",
    "    crop_data_scaled = standardize_data(crop_data)\n",
    "    \n",
    "    # Perform spectral clustering with 5 clusters\n",
    "    labels = perform_spectral_clustering(crop_data_scaled, 5)\n",
    "    \n",
    "    # Add the cluster labels to the original dataframe\n",
    "    df_agg_00_23[f'{crop}_Spectral_Cluster_Custom'] = np.nan\n",
    "    df_agg_00_23.loc[indices, f'{crop}_Spectral_Cluster_Custom'] = labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df_agg_00_23 is already loaded\n",
    "crops = ['Canola', 'Spring Wheat', 'Durum', 'Oats', 'Lentils', 'Peas', 'Barley']\n",
    "\n",
    "# Function to prepare data for each crop\n",
    "def prepare_data_for_crop(df, crop):\n",
    "    columns = [f'{crop}_mean', f'{crop}_std']\n",
    "    crop_data = df[columns].dropna().values\n",
    "    return crop_data, df[columns].dropna().index\n",
    "\n",
    "# Standardize the data\n",
    "def standardize_data(data):\n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = scaler.fit_transform(data)\n",
    "    return data_scaled\n",
    "\n",
    "# Function to perform K-Means clustering\n",
    "def kmeans_clustering(data, n_clusters):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "    labels = kmeans.fit_predict(data)\n",
    "    return labels\n",
    "\n",
    "# Function to find the optimal number of clusters using the Elbow method\n",
    "def find_optimal_clusters(data, max_k):\n",
    "    distortions = []\n",
    "    for k in range(1, max_k+1):\n",
    "        kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "        kmeans.fit(data)\n",
    "        distortions.append(kmeans.inertia_)\n",
    "    optimal_k = distortions.index(min(distortions[1:])) + 1\n",
    "    return optimal_k, distortions\n",
    "\n",
    "# Iterate over each crop and perform clustering\n",
    "for crop in crops:\n",
    "    # Prepare the data for the crop\n",
    "    crop_data, indices = prepare_data_for_crop(df_agg_00_23, crop)\n",
    "    \n",
    "    # Standardize the data\n",
    "    crop_data_scaled = standardize_data(crop_data)\n",
    "    \n",
    "    # Find the optimal number of clusters using the Elbow method\n",
    "    optimal_k, distortions = find_optimal_clusters(crop_data_scaled, 10)\n",
    "    \n",
    "    # Perform K-Means clustering with the optimal number of clusters\n",
    "    optimal_labels = kmeans_clustering(crop_data_scaled, optimal_k)\n",
    "    \n",
    "    # Perform K-Means clustering with 5 clusters\n",
    "    fixed_labels = kmeans_clustering(crop_data_scaled, 5)\n",
    "    \n",
    "    # Add the cluster labels to the original dataframe\n",
    "    df_agg_00_23[f'{crop}_KMeans_Cluster_Optimal'] = np.nan\n",
    "    df_agg_00_23[f'{crop}_KMeans_Cluster_Custom'] = np.nan\n",
    "    df_agg_00_23.loc[indices, f'{crop}_KMeans_Cluster_Optimal'] = optimal_labels\n",
    "    df_agg_00_23.loc[indices, f'{crop}_KMeans_Cluster_Custom'] = fixed_labels\n",
    "    \n",
    "    # Plot the Elbow method graph\n",
    "    plt.plot(range(1, 11), distortions, marker='o')\n",
    "    plt.title(f'Elbow Method for {crop}')\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('Distortion')\n",
    "    plt.show()\n",
    "\n",
    "# Display the dataframe with the new cluster columns\n",
    "df_agg_00_23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ranking Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of crops and corresponding cluster columns\n",
    "crops_clusters = {\n",
    "    'Canola': ['Canola_Spectral_Cluster_Optimal', 'Canola_Spectral_Cluster_Custom', 'Canola_KMeans_Cluster_Optimal', 'Canola_KMeans_Cluster_Custom'],\n",
    "    'Spring Wheat': ['Spring Wheat_Spectral_Cluster_Optimal', 'Spring Wheat_Spectral_Cluster_Custom', 'Spring Wheat_KMeans_Cluster_Optimal', 'Spring Wheat_KMeans_Cluster_Custom'],\n",
    "    'Durum': ['Durum_Spectral_Cluster_Optimal', 'Durum_Spectral_Cluster_Custom', 'Durum_KMeans_Cluster_Optimal', 'Durum_KMeans_Cluster_Custom'],\n",
    "    'Oats': ['Oats_Spectral_Cluster_Optimal', 'Oats_Spectral_Cluster_Custom', 'Oats_KMeans_Cluster_Optimal', 'Oats_KMeans_Cluster_Custom'],\n",
    "    'Lentils': ['Lentils_Spectral_Cluster_Optimal', 'Lentils_Spectral_Cluster_Custom', 'Lentils_KMeans_Cluster_Optimal', 'Lentils_KMeans_Cluster_Custom'],\n",
    "    'Peas': ['Peas_Spectral_Cluster_Optimal', 'Peas_Spectral_Cluster_Custom', 'Peas_KMeans_Cluster_Optimal', 'Peas_KMeans_Cluster_Custom'],\n",
    "    'Barley': ['Barley_Spectral_Cluster_Optimal', 'Barley_Spectral_Cluster_Custom', 'Barley_KMeans_Cluster_Optimal', 'Barley_KMeans_Cluster_Custom']\n",
    "}\n",
    "\n",
    "# Initialize a new DataFrame for ranked columns\n",
    "df_agg_00_23_ranked = df_agg_00_23.copy()\n",
    "\n",
    "# Rank the clusters based on the mean crop yield for each crop\n",
    "for crop, clusters in crops_clusters.items():\n",
    "    mean_column = f'{crop}_mean'\n",
    "    \n",
    "    for cluster_col in clusters:\n",
    "        # Calculate the mean crop yield grouped by the cluster column\n",
    "        cluster_means = df_agg_00_23.groupby(cluster_col).mean()[mean_column]\n",
    "        \n",
    "        # Rank the clusters based on the mean crop yield\n",
    "        df_agg_00_23_ranked[f'{cluster_col}_ranked'] = df_agg_00_23[cluster_col].map(cluster_means.rank(method='min'))\n",
    "\n",
    "# Drop old unranked cluster columns\n",
    "for clusters in crops_clusters.values():\n",
    "    df_agg_00_23_ranked.drop(columns=clusters, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Final Dataframe to get geojson data\n",
    "\n",
    "final= df_agg_00_23_ranked.merge(gdf_rm_clean, on = 'RM', how='left')\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.GeoDataFrame(final, geometry='geometry')\n",
    "\n",
    "# Save the GeoDataFrame to a GeoJSON file\n",
    "gdf.to_file('output_geojson.geojson', driver='GeoJSON')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
